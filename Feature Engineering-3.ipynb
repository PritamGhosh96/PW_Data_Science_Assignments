{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "695fc7ea",
   "metadata": {},
   "source": [
    "###### Q1. What is Min-Max scaling, and how is it used in data preprocessing? Provide an example to illustrate its application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b915e3b0",
   "metadata": {},
   "source": [
    "Rescaling (min-max normalization) Also known as min-max scaling or min-max normalization, rescaling is the simplest method and consists in rescaling the range of features to scale the range in [0, 1] or [−1, 1]. Selecting the target range depends on the nature of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719b51d3",
   "metadata": {},
   "source": [
    "This transformation is often used as an alternative to zero mean, unit variance scaling.\n",
    "MinMaxScaler doesn’t reduce the effect of outliers, but it linearily scales them down into a fixed range, where the largest occuring data point corresponds to the maximum value and the smallest one corresponds to the minimum value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016174e5",
   "metadata": {},
   "source": [
    "Example: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "122758e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [[-1, 2], [-0.5, 6], [0, 10], [1, 18]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d726640a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  ],\n",
       "       [0.25, 0.25],\n",
       "       [0.5 , 0.5 ],\n",
       "       [1.  , 1.  ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit_transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b79a78",
   "metadata": {},
   "source": [
    "###### Q2. What is the Unit Vector technique in feature scaling, and how does it differ from Min-Max scaling? Provide an example to illustrate its application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab1b845",
   "metadata": {},
   "source": [
    "Unit vector scaling is done keeping in mind the whole feature vector in a unit length. This normally requires dividing each component by the Euclidean length of the vector."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f049ce",
   "metadata": {},
   "source": [
    "min-max scaling done on a column in a dataframe while Unit Vector technique is applied on a row of a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "821e836a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dbe6acf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [[4, 1, 2, 2],\n",
    "    [1, 3, 9, 3],\n",
    "    [5, 7, 5, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4b03ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = Normalizer().fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "613e8ff0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8, 0.2, 0.4, 0.4],\n",
       "       [0.1, 0.3, 0.9, 0.3],\n",
       "       [0.5, 0.7, 0.5, 0.1]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8a940b",
   "metadata": {},
   "source": [
    "###### Q3. What is PCA (Principle Component Analysis), and how is it used in dimensionality reduction? Provide an example to illustrate its application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fcddb47",
   "metadata": {},
   "source": [
    "Principal Component Analysis is an unsupervised learning algorithm that is used for the dimensionality reduction in machine learning. Reducing the number of variables in a data collection while retaining as much information as feasible is the main goal of PCA. PCA can be mainly used for Dimensionality Reduction and also for important feature selection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0911c3ea",
   "metadata": {},
   "source": [
    "It transforms the p number of input variables into a smaller k (k << p) number of uncorrelated variables called principal components by taking advantage of the existing correlations between the input variables in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc80d39c",
   "metadata": {},
   "source": [
    "###### Q4. What is the relationship between PCA and Feature Extraction, and how can PCA be used for Feature Extraction? Provide an example to illustrate this concept."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc95c96",
   "metadata": {},
   "source": [
    "PCA is a part of Feature Extraction whereit is used to reduce the number of Features while keeping the feesible data intact."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4bb47f4",
   "metadata": {},
   "source": [
    "###### Q5. You are working on a project to build a recommendation system for a food delivery service. The dataset contains features such as price, rating, and delivery time. Explain how you would use Min-Max scaling to preprocess the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6708a89d",
   "metadata": {},
   "source": [
    "we can use [0, 1] normalization on price and delivery time and can use [-1,1] normalization on price to get bad and good quality rating."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a8e6e2",
   "metadata": {},
   "source": [
    "###### Q6. You are working on a project to build a model to predict stock prices. The dataset contains many features, such as company financial data and market trends. Explain how you would use PCA to reduce the dimensionality of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1949c6b0",
   "metadata": {},
   "source": [
    "We can create PC using highly co-releated data in a gruops to create seperate groups. For Example, We can create a PC using a Company Financial data another using Market sentiment data. Likewise we can reduce the features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7072050",
   "metadata": {},
   "source": [
    "###### Q7. For a dataset containing the following values: [1, 5, 10, 15, 20], perform Min-Max scaling to transform the values to a range of -1 to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c73bf750",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1.0, -0.5789473684210527, -0.052631578947368474, 0.4736842105263157, 1.0]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [1, 5, 10, 15, 20]\n",
    "min = min(data)\n",
    "max = max(data)\n",
    "\n",
    "def scaler(val):\n",
    "    return -1+((val-min)*(1-(-1)))/(max-min)\n",
    "\n",
    "list(map(scaler, data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc08c2e6",
   "metadata": {},
   "source": [
    "###### Q8. For a dataset containing the following features: [height, weight, age, gender, blood pressure], perform Feature Extraction using PCA. How many principal components would you choose to retain, and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee4612b",
   "metadata": {},
   "source": [
    "I will choose height, weight age and gender to create a PC as they are highly co releated and use blood pressure as it is as it is not highly co related with other features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd66172",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
