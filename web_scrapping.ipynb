{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49155487",
   "metadata": {},
   "source": [
    "###### Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307f5075",
   "metadata": {},
   "source": [
    "Web scraping is an automatic method to obtain large amounts of data from websites. Most of this data is unstructured data in an HTML format which is then converted into structured data in a spreadsheet or a database so that it can be used in various applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10cf412",
   "metadata": {},
   "source": [
    "1. E-Commerce\n",
    "\n",
    "Web Scraping can be used to periodically extract data of products from various e-commerce websites like Amazon, eBay, Google Shopping etc. Product details like price, description, images, reviews, rating etc. can be easily extracted using a web scraping software. \n",
    "\n",
    "2. Data Analysis\n",
    "\n",
    "Using a Web Scraper you can extract data from multiple websites to a single spreadsheet (or database) so that it becomes easy for you to analyze (or even visualize) the data.\n",
    "\n",
    "3. Training and Testing Data for Machine Learning Projects\n",
    "\n",
    "Web Scraping helps you to gather data for testing / training your Machine Learning models. Quality of your machine learning models depends on the quality of training data used and when the data is not readily available you can employ web scraping to collect it from various websites. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fe7dbb",
   "metadata": {},
   "source": [
    "###### Q2. What are the different methods used for Web Scraping?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ca1025",
   "metadata": {},
   "source": [
    "The most common techniques used for Web Scraping are\n",
    "\n",
    "    Human copy-and-paste.\n",
    "    Text pattern matching.\n",
    "    HTTP programming.\n",
    "    HTML parsing.\n",
    "    DOM parsing.\n",
    "    Vertical aggregation.\n",
    "    Semantic annotation recognizing.\n",
    "    Computer vision web-page analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d24f07",
   "metadata": {},
   "source": [
    "###### Q3. What is Beautiful Soup? Why is it used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42be07e0",
   "metadata": {},
   "source": [
    "Beautiful Soup is a python package and as the name suggests, parses the unwanted data and helps to organize and format the messy web data by fixing bad HTML and present to us in an easily-traversible XML structures.\n",
    "\n",
    "In short, Beautiful Soup is a python package which allows us to pull data out of HTML and XML documents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71230aa6",
   "metadata": {},
   "source": [
    "Beautiful Soup is a Python library for web scraping and parsing HTML and XML documents, giving us more options to navigate through a structured data tree. The library can parse and navigate through the page, allowing you to extract information from the HTML or XML code by providing a simple, easy-to-use API."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8b2711",
   "metadata": {},
   "source": [
    "###### Q4. Why is flask used in this Web Scraping project?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc4e229",
   "metadata": {},
   "source": [
    "Flask is a python library to create web api. Using flask in this project we made the project acccessable on the web so anyone can use our web-scrapping app from all over the world. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4416373",
   "metadata": {},
   "source": [
    "###### Q5. Write the names of AWS services used in this project. Also, explain the use of each service."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7773cf",
   "metadata": {},
   "source": [
    "AWS sevices used in this project were :\n",
    "    \n",
    "    1. Code Pipeline - It was used to push the code from git hub to AWS.\n",
    "    2. BeanStack - It provided us the service of creating a virtual machine with python environment where deployed our code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e269fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
