{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "394c3a14",
   "metadata": {},
   "source": [
    "###### Q1. What is Lasso Regression, and how does it differ from other regression techniques?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85130ee1",
   "metadata": {},
   "source": [
    "Lasso is a modification of linear regression, where the model is penalized for the sum of absolute values of the weights. Thus, the absolute values of weight will be (in general) reduced, and many will tend to be zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53fbe83",
   "metadata": {},
   "source": [
    "The difference lies in the loss function used – Lasso Regression uses L1 regularization, which aims to minimize the sum of the absolute values of coefficients multiplied by penalty factor λ. Unlike Ridge Regression, Lasso Regression can force coefficients of less significant features to be exactly zero."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbe95cf",
   "metadata": {},
   "source": [
    "###### Q2. What is the main advantage of using Lasso Regression in feature selection?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1667270",
   "metadata": {},
   "source": [
    " The main advantage of a LASSO regression model is that it has the ability to set the coefficients for features it does not consider interesting to zero. This means that the model does some automatic feature selection to decide which features should and should not be included on its own."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b2c2df",
   "metadata": {},
   "source": [
    "###### Q3. How do you interpret the coefficients of a Lasso Regression model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b644ecd1",
   "metadata": {},
   "source": [
    "Lasso regression and force coefficients toward 0. The smaller the coefficient the less important it is or less variance it explains. The actual value here will be less important since it will be used in logistic regression because it will end up being used in an exponential"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef4d593",
   "metadata": {},
   "source": [
    "###### Q4. What are the tuning parameters that can be adjusted in Lasso Regression, and how do they affect the model's performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3537d1b7",
   "metadata": {},
   "source": [
    "Lasso introduces bias into ordinary least squares to combat overfitting. The hyperparameter in this equation is denoted by λ (lambda). A larger value chosen for λ will result in a greater quantity of bias introduced into the algorithm's output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34bc8558",
   "metadata": {},
   "source": [
    "###### Q5. Can Lasso Regression be used for non-linear regression problems? If yes, how?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6129bd6f",
   "metadata": {},
   "source": [
    "If you can linearize the model, then yes but for an approximate solution in the LS sense since what is measured is y and not any of its possible transforms. If you model is nonlinear because of one parameter, there are things which can be done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86b6e3a",
   "metadata": {},
   "source": [
    "###### Q6. What is the difference between Ridge Regression and Lasso Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebc2f59",
   "metadata": {},
   "source": [
    "Ridge Regression adds a penalty term proportional to the square of the coefficients, while Lasso adds a penalty term proportional to the absolute value of the coefficients, which can lead to variable selection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00bca4fc",
   "metadata": {},
   "source": [
    "###### Q7. Can Lasso Regression handle multicollinearity in the input features? If yes, how?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea42336",
   "metadata": {},
   "source": [
    "With multiple linear regression, this can cause your coefficients to vary dramatically and throw off the interpretability of your model. Luckily, because of LASSO's built-in variable selection, it can handle some multicollinearity without sacrificing interpretability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a13f627",
   "metadata": {},
   "source": [
    "###### Q8. How do you choose the optimal value of the regularization parameter (lambda) in Lasso Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3937a39a",
   "metadata": {},
   "source": [
    "Cross-validation is a way to tune the hyperparameters using only the training data. There are different variations of cross-validation, but the most common one is 10-Fold Cross-Validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9512c849",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
