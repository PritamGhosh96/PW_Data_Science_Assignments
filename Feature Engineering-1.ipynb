{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "030cb495",
   "metadata": {},
   "source": [
    "### Q1: What are missing values in a dataset? Why is it essential to handle missing values? Name some algorithms that are not affected by missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bca4ab",
   "metadata": {},
   "source": [
    "### 1. Missing Completely at Random, MCAR:\n",
    "\n",
    "Missing completely at random (MCAR) is a type of missing data mechanism in which the probability of a value being missing is unrelated to both the observed data and the missing data. In other words, if the data is MCAR, the missing values are randomly distributed throughout the dataset, and there is no systematic reason for why they are missing.\n",
    "\n",
    "For example, in a survey about the prevalence of a certain disease, the missing data might be MCAR if the survey participants with missing values for certain questions were selected randomly and their missing responses are not related to their disease status or any other variables measured in the survey.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf6c8eb",
   "metadata": {},
   "source": [
    "### 2. Missing at Random MAR:\n",
    "Missing at Random (MAR) is a type of missing data mechanism in which the probability of a value being missing depends only on the observed data, but not on the missing data itself. In other words, if the data is MAR, the missing values are systematically related to the observed data, but not to the missing data.\n",
    "Here are a few examples of missing at random:\n",
    "\n",
    "Income data: Suppose you are collecting income data from a group of people, but some participants choose not to report their income. If the decision to report or not report income is related to the participant's age or gender, but not to their income level, then the data is missing at random.\n",
    "\n",
    "Medical data: Suppose you are collecting medical data on patients, including their blood pressure, but some patients do not report their blood pressure. If the patients who do not report their blood pressure are more likely to be younger or have healthier lifestyles, but the missingness is not related to their actual blood pressure values, then the data is missing at random."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3d7317",
   "metadata": {},
   "source": [
    "### 3. Missing data not at random (MNAR)\n",
    "It is a type of missing data mechanism where the probability of missing values depends on the value of the missing data itself. In other words, if the data is MNAR, the missingness is not random and is dependent on unobserved or unmeasured factors that are associated with the missing values.\n",
    "\n",
    "For example, suppose you are collecting data on the income and job satisfaction of employees in a company. If employees who are less satisfied with their jobs are more likely to refuse to report their income, then the data is not missing at random. In this case, the missingness is dependent on job satisfaction, which is not directly observed or measured."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf30b86",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "48d0bcef",
   "metadata": {},
   "source": [
    "If not properly managed, missing values can lead to biased or inaccurate models. \n",
    "The approach to handling missing values (e.g., imputation, deletion, or using them as a feature) can impact the performance of the model and the insights you can derive from the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e0f6b9",
   "metadata": {},
   "source": [
    "The k-NN algorithm can ignore a column from a distance measure when a value is missing. Naive Bayes can also support missing values when making a prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ed52f4",
   "metadata": {},
   "source": [
    "### Q2: List down techniques used to handle missing data. Give an example of each with python code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a07e8be",
   "metadata": {},
   "source": [
    "Some Techniques to handle missing values are :\n",
    "\n",
    "    1. Deletion of Rows : - We can delete the rows with null value. Using it fruitful when the number of rows with null value is very small compare to the dataset.\n",
    "    \n",
    "    2. Deletion of Columns :- We can delete the cols with null value. Using it fruitful when maximum data for a column is null.\n",
    "    \n",
    "    3. Mean Imputation :- Replacing null data with the Mean of the column data. Using it fruitful when the Data follows a normal Distribution.\n",
    "    \n",
    "    4. Median Imputation :- Replacing null data with the Median of the column data. Using it fruitful when the Data has some outliers.\n",
    "    \n",
    "    5. Mode Imputation :- Replacing null data with the Mode of the column data. Using it fruitful when the Data is categorical in type."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc998af2",
   "metadata": {},
   "source": [
    "### Q3: Explain the imbalanced data. What will happen if imbalanced data is not handled?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac50f33",
   "metadata": {},
   "source": [
    "When presence of a certain class of data is relatively very higher than the other classes we call it an imbalance in the dataset.\n",
    "\n",
    "If the imbalamce is not handled properly the model will be biased and there will be inaccuracy while predicting the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391c2a20",
   "metadata": {},
   "source": [
    "### Q4: What are Up-sampling and Down-sampling? Explain with an example when up-sampling and down-sampling are required."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42bc0553",
   "metadata": {},
   "source": [
    "Up-sampling:- Up-sampling is creating data points for minority of the dataset.\n",
    "<br>Down-sampling:- Down-sampling is removing datapoints for majority of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20e89bd",
   "metadata": {},
   "source": [
    "For Example, If there is a dataset with 1000 entries and for a column \"Target\" there is two data, \"A\" and \"B\". If A has 900 data and B has 100 then this is a clear case of Data Imbalance. In this case, we can add 800 more data for B, this will be known as up-sampling. Or, we can remove 800 data for A, this will be known as down-sampling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e457d2bf",
   "metadata": {},
   "source": [
    "### Q5: What is data Augmentation? Explain SMOTE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57da68da",
   "metadata": {},
   "source": [
    "Data augmentation is a technique of artificially increasing the training set by creating modified copies of a dataset using existing data. It includes making minor changes to the dataset or using deep learning to generate new data points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0fe52c",
   "metadata": {},
   "source": [
    "SMOTE (Synthetic Minority Oversampling Technique) is an oversampling method of balancing class distribution in the dataset. It selects the minority examples that are close to the feature space. Then, it draws the line between the examples in the features space and draws a new sample at a point along that line."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f60c7b",
   "metadata": {},
   "source": [
    "### Q6: What are outliers in a dataset? Why is it essential to handle outliers?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf580882",
   "metadata": {},
   "source": [
    "Outliers are extreme values that differ from most other data points in a dataset. They can have a big impact on your statistical analyses and skew the results of any hypothesis tests."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1356c7",
   "metadata": {},
   "source": [
    "One of the most important steps as part of data preprocessing is detecting and treating the outliers as they can negatively affect the statistical analysis and the training process of a machine learning algorithm resulting in lower accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1439b12b",
   "metadata": {},
   "source": [
    "### Q7: You are working on a project that requires analyzing customer data. However, you notice that some of the data is missing. What are some techniques you can use to handle the missing data in your analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ac07ed",
   "metadata": {},
   "source": [
    "It depends on the data. If\n",
    "\n",
    "    1. Some rows has multiple data missing - Daletion of Rows\n",
    "    2. A column missing most data - Delete the Column\n",
    "    3. A column missing some data with normal distribution - Mean Imputation\n",
    "    4. A column missing some data with skewed distribution - Medial Imputation\n",
    "    5. A column missing some categorical data - Mode Imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4312d3af",
   "metadata": {},
   "source": [
    "### Q8: You are working with a large dataset and find that a small percentage of the data is missing. What are some strategies you can use to determine if the missing data is missing at random or if there is a pattern to the missing data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d3c016",
   "metadata": {},
   "source": [
    "One common approach is to use statistical tests, such as Little's test or the Missing Completely at Random (MCAR) test, to assess whether the missing data is related to the observed data. These tests can help determine if the missing data is likely to be random or if there is a systematic pattern to the missingness."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be0b570",
   "metadata": {},
   "source": [
    "### Q9: Suppose you are working on a medical diagnosis project and find that the majority of patients in the dataset do not have the condition of interest, while a small percentage do. What are some strategies you can use to evaluate the performance of your machine learning model on this imbalanced dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0bf951",
   "metadata": {},
   "source": [
    "We can use Up-sampling for interested patients or Down-sampling for noninterseted patients or can use both of them to balance the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a42d25",
   "metadata": {},
   "source": [
    "### Q10: When attempting to estimate customer satisfaction for a project, you discover that the dataset is unbalanced, with the bulk of customers reporting being satisfied. What methods can you employ to balance the dataset and down-sample the majority class?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49eea2d",
   "metadata": {},
   "source": [
    "We can downsample satisfied datapoints and upweight the satisfied class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f377cd4",
   "metadata": {},
   "source": [
    "### Q11: You discover that the dataset is unbalanced with a low percentage of occurrences while working on a project that requires you to estimate the occurrence of a rare event. What methods can you employ to balance the dataset and up-sample the minority class?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc5bb70",
   "metadata": {},
   "source": [
    "We can use SMOTE to create more samples for minority class in-between the data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3d72d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
